{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append Data from SDE into Feature Service\n",
    "\n",
    "The script utilizes both Esri's Destkop Python library 'arcpy' & the web Python API.  Connect to ArcGIS Online or Enterprise\n",
    "parse through various datapoints and package them up for append operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import json\n",
    "import arcpy\n",
    "import getpass\n",
    "import shutil\n",
    "import time\n",
    "from arcpy import env\n",
    "from arcgis.gis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to delete temporary files\n",
    "def delete_json(temp_file, value):\n",
    "    if value == 0:\n",
    "        if os.path.exists(temp_file):\n",
    "            try:\n",
    "                os.remove(temp_file)\n",
    "            except OSError as e:  ## if failed, report it back to the user ##\n",
    "                print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
    "    else:\n",
    "        try:\n",
    "            if arcpy.Exists(temp_file):\n",
    "                arcpy.Delete_management(temp_file)\n",
    "            else:\n",
    "                pass\n",
    "        except (arcpy.ExecuteError, arcpy.ExecuteWarning) as e:\n",
    "            print(\"Error: %s\" % e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yield successive n-sized chunks from l.\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to ArcGIS Online - Python API\n",
    "Estbalish connection, search for content by name to return the item's ID.  Once found, connect to relevant index dataset, and truncate the service in preparation for data load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "# Utilize getpass for hiding password for demonstration purposes\n",
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish connection to a WebGIS organization\n",
    "# ArcGIS Online\n",
    "#gis = GIS('http://www.arcgis.com', 'abrown_citygov', password)\n",
    "\n",
    "# For ArcGIS Enterprise, connect as \"https:<server DNS>/<web adaptor for portal>\"\n",
    "gis = GIS('http://neenterprise.esri.com/portal', 'username', password)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Item title:\"PhillyCrimeExample\" type:Feature Layer Collection owner:abrown_citygov>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search by title\n",
    "search = gis.content.search(query=\"title: PhillyCrimeExample\", item_type=\"Feature Service\")\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1d1ee09e66084db0a189ee0e86ba9689'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From search list, return the index for service one is interseted in connecting to\n",
    "item = search[0]\n",
    "itemID = item.id\n",
    "itemID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FeatureLayer url:\"https://services6.arcgis.com/0p6i4J6xhQas4Unf/arcgis/rest/services/PhillyCrimeExample/FeatureServer/0\">"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish connection to Feature Layer item\n",
    "feature_layer_item = gis.content.get(itemID)\n",
    "flayers = feature_layer_item.layers\n",
    "flayer = flayers[0]\n",
    "flayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Truncate the dataset, cannot be utlized on layers with synch\n",
    "flayer.manager.truncate()\n",
    "\n",
    "# Alternative Option, utilize delete_features method in class FeatureLayer\n",
    "# flayer.delete_features(where=\"1=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to Enterprise Geodatabase\n",
    "\n",
    "Establish connection to enterprise geodatabase.  List feature classes, locate dataset of interest. Convert dataset into a json file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish arcpy desktop workspace\n",
    "wspace = r'D:\\NYPD\\complaints.gdb'\n",
    "env.workspace = wspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Feature Classes in Enterprise Geodatabase\n",
    "fclist = arcpy.ListFeatureClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate dataset of interest\n",
    "for item in fclist:\n",
    "    if item == 'complaints':\n",
    "        # Establish dataset name\n",
    "        datasetname = item.rsplit('.', 1)[1]\n",
    "        \n",
    "        # Create temporary in memory layer for conversion to json\n",
    "        arcpy.MakeFeatureLayer_management(item, \"layer\")\n",
    "        \n",
    "        # Create placeholder for temporary json file\n",
    "        temp_json = r'D:\\Scratch\\jsons_' + datasetname + '.json'\n",
    "        \n",
    "        # Make sure temporary json does not exist\n",
    "        delete_json(temp_json, 0)\n",
    "\n",
    "        # Convert dataset into json file\n",
    "        arcpy.FeaturesToJSON_conversion(\"layer\", temp_json)\n",
    "\n",
    "        # Delete temporary memory layer\n",
    "        arcpy.Delete_management(\"layer\")\n",
    "        \n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for insert into Feature Service\n",
    "\n",
    "Convert to a file geodatabase (only method to utilize append and preserve schema matching without a data dictionary). Zip up the file geodatabase and add the content to ArcGIS Online. Append the new data to an existing feature service.  Delete all temporary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of features: 104265\n",
      "D:\\Scratch\\fgdb\\item0.gdb\n",
      "Adding Item...\n",
      "Done Adding Item\n",
      "title:item0.gdb\n",
      "[<Item title:\"item0.gdb\" type:File Geodatabase owner:abrown_citygov>]\n",
      "D:\\Scratch\\fgdb\\item1.gdb\n",
      "Adding Item...\n",
      "Done Adding Item\n",
      "title:item1.gdb\n",
      "[<Item title:\"item1.gdb\" type:File Geodatabase owner:abrown_citygov>]\n",
      "D:\\Scratch\\fgdb\\item2.gdb\n",
      "Adding Item...\n",
      "Done Adding Item\n",
      "title:item2.gdb\n",
      "[<Item title:\"item2.gdb\" type:File Geodatabase owner:abrown_citygov>]\n"
     ]
    }
   ],
   "source": [
    "# Open json exported from enterprise dataset\n",
    "file = open(temp_json)\n",
    "content = json.loads(file.read())\n",
    "\n",
    "# Identify json sections to build into smaller json dictionary in subsequent sections.\n",
    "display = (content[\"displayFieldName\"])\n",
    "alias = (content[\"fieldAliases\"])\n",
    "geomtype = (content[\"geometryType\"])\n",
    "spatref = (content[\"spatialReference\"])\n",
    "fields = (content[\"fields\"])\n",
    "new_features = (content[\"features\"])\n",
    "\n",
    "print('Total Number of features: %s' % (len(new_features)))\n",
    "\n",
    "# Utilize the chunks generator to create groups of 50000 features\n",
    "# Upper limit seems to be in the neighborhood of 250K - 350K, depending on the complexity of the datasets.\n",
    "new_items = chunks(new_features, 50000)\n",
    "\n",
    "# Loop through items created into smaller chunks\n",
    "for i, item in enumerate(new_items):\n",
    "    \n",
    "    # Create a new diciontary to build proper json (reconstructing with less features)\n",
    "    json_dict = {}\n",
    "    json_dict['displayFieldName'] = display\n",
    "    json_dict['fieldAliases'] = alias\n",
    "    json_dict['geometryType'] = geomtype\n",
    "    json_dict['spatialReference'] = spatref\n",
    "    json_dict['fields'] = fields\n",
    "    json_dict['features'] = item\n",
    "\n",
    "    # Output variables for temporary output type & locations\n",
    "    output = r'D:\\Scratch\\jsons\\new_json_' + str(i) + '.json'\n",
    "    outzipdir = r'D:\\Scratch\\zip'\n",
    "    outshapedir = r'D:\\Scratch\\fgdb'\n",
    "    output2 = r'D:\\Scratch\\fgdb\\item' + str(i) + '.gdb'\n",
    "    fname = output2.rsplit('\\\\', 1)[-1]\n",
    "\n",
    "    # Create a File Geodatabase to be zipped\n",
    "    print(os.path.join(outshapedir, fname))\n",
    "    arcpy.CreateFileGDB_management(outshapedir, fname)\n",
    "    zipname = fname.rsplit('.', 1)[0]\n",
    "   \n",
    "    # Open temporary subset json file, write reconstructed dictionary as content.\n",
    "    with open(output, 'w') as outfile:\n",
    "        json.dump(json_dict, outfile, ensure_ascii=False)\n",
    "\n",
    "    # Convert new subset json file to feature class in the file geodatabase\n",
    "    arcpy.JSONToFeatures_conversion(in_json_file=output, out_features=os.path.join(output2, str(fname).split('.')[0]))\n",
    "\n",
    "    # Delete subset json temporary file\n",
    "    delete_json(output, 0)\n",
    "    finalname = outzipdir + '\\\\' + zipname + '.gdb'\n",
    "    \n",
    "    # Establish name of the output zip file\n",
    "    deletezip = finalname + '.zip'\n",
    "\n",
    "    # Zip up the contents of the fgdb folder properly to ensure data hierarchy \n",
    "    shutil.make_archive(finalname, \"zip\", outshapedir)\n",
    "    time.sleep(30)\n",
    "    delete_json(output2, 1)\n",
    "\n",
    "    # Create item properties \n",
    "    item_properties = {'title': fname,\n",
    "                       'description': 'Append testing',\n",
    "                       'type': 'File Geodatabase',\n",
    "                       'tags': 'test',\n",
    "                       'thumbnail': r\"C:\\Users\\alex8694\\Pictures\\Logos\\esri.png\" }\n",
    "    \n",
    "    print('Adding Item...')\n",
    "    \n",
    "    # Add content to ArcGIS Online/Enterprise as an item\n",
    "    gis.content.add(item_properties=item_properties, data=deletezip)\n",
    "\n",
    "    print('Done Adding Item')\n",
    "\n",
    "    # Establish query based upon item index name\n",
    "    query = \"title:\" + str(fname)\n",
    "    print(query)\n",
    "    \n",
    "    # Extra time to ensure upload process completed \n",
    "    time.sleep(10)\n",
    "    \n",
    "    # Search for new temporary file geodatabase item\n",
    "    search = gis.content.search(query=query, item_type=\"File Geodatabase\")\n",
    "    print(search)\n",
    "    item = search[0]\n",
    "    \n",
    "    # Temporary item id\n",
    "    new_item = item.id\n",
    "    \n",
    "    # Complete the append operation on the base service\n",
    "    try:\n",
    "        flayer.append(item_id=new_item, upload_format='filegdb')\n",
    "    except TypeError:\n",
    "        # Numerous errors occur when item uploaded has not full loaded\n",
    "        \n",
    "        # Repeat time to wait and try again\n",
    "        time.sleep(10)\n",
    "\n",
    "        # Search for new temporary file geodatabase item\n",
    "        search = gis.content.search(query=query, item_type=\"File Geodatabase\")\n",
    "        item = search[0]\n",
    "\n",
    "        # Temporary item id\n",
    "        new_item = item.id\n",
    "        flayer.append(item_id=new_item, upload_format='filegdb')\n",
    "\n",
    "    # Delete temporary file geodatabase on ArcGIS Online/Enterprise\n",
    "    item_for_deletion = gis.content.get(new_item)\n",
    "    item_for_deletion.delete()\n",
    "\n",
    "    # Delete temporary zip file\n",
    "    delete_json(deletezip, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104265\n"
     ]
    }
   ],
   "source": [
    "# Close master json file\n",
    "file.close()\n",
    "\n",
    "# Return total record count\n",
    "query_result = flayer.query(where='1=1', out_fields='*')\n",
    "print(len(query_result))\n",
    "\n",
    "# Delete master json file for dataset\n",
    "delete_json(temp_json, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
